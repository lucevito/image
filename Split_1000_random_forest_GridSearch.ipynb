{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPVG4JbXLZwIbeJP+0ZwwO0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucevito/image/blob/main/Split_1000_random_forest_GridSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6cm4yTyDP7C",
        "outputId": "77784ef1-8511-4957-fc50-687cbd401ba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "import joblib\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "import os\n",
        "import pandas as pd\n",
        "from openpyxl import Workbook, load_workbook\n",
        "from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "\n",
        "\n",
        "def loaddataset(directory):\n",
        "  images_files = glob.glob(directory + '/images' + '/*.npy')\n",
        "  masks_files = glob.glob(directory + '/masks' + '/*.npy')\n",
        "  x = np.array([np.load(file) for file in images_files])\n",
        "  y = np.array([np.load(file) for file in masks_files])\n",
        "  x = x.reshape(len(x) * len(x[0]) * len(x[0][0]), 10)\n",
        "  y = y.reshape(len(y) * len(y[0]) * len(y[0][0]), 1)\n",
        "  y = np.ravel(y)\n",
        "  return x,y\n",
        "\n",
        "def rflearn(X,Y,filename):\n",
        "  rf_model = RandomForestClassifier(random_state=42)\n",
        "  rf_model.fit(X, Y)\n",
        "  joblib.dump(rf_model, filename)\n",
        "\n",
        "def rftest(test,filename):\n",
        "  rf_model = joblib.load(filename)\n",
        "  predictions = rf_model.predict(test)\n",
        "  return predictions\n",
        "\n",
        "def grindsearch(param_grid,X,Y,filename):\n",
        "  rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "  grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='roc_auc')\n",
        "  grid_search.fit(X, Y)\n",
        "\n",
        "  best_params = grid_search.best_params_\n",
        "  best_score = grid_search.best_score_\n",
        "\n",
        "  best_rf_model = RandomForestClassifier(**best_params, random_state=42)\n",
        "  best_rf_model.fit(X, Y)\n",
        "  joblib.dump(best_rf_model, filename)\n",
        "\n",
        "def selectSet(X, Y, target_class):\n",
        "  mask = (Y == target_class)\n",
        "  selectionX = X[mask]\n",
        "  selectionY = Y[mask]\n",
        "  return selectionX, selectionY\n",
        "\n",
        "def sampling(X, Y, n):\n",
        "    indices = np.random.choice(len(X), n, replace=False)\n",
        "    sampleX = X[indices]\n",
        "    sampleY = Y[indices]\n",
        "    return sampleX, sampleY\n",
        "\n",
        "def concatenate(X1, X2, Y1, Y2):\n",
        "    X = np.concatenate((X1, X2), axis=0)\n",
        "    Y = np.concatenate((Y1, Y2), axis=0)\n",
        "    return X, Y\n",
        "\n",
        "def print_metrics(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    precision_negative = precision_score(y_true, y_pred, pos_label=0)\n",
        "    recall_negative = recall_score(y_true, y_pred, pos_label=0)\n",
        "    fscore_negative = f1_score(y_true, y_pred, pos_label=0)\n",
        "    precision_positive = precision_score(y_true, y_pred, pos_label=1)\n",
        "    recall_positive = recall_score(y_true, y_pred, pos_label=1)\n",
        "    fscore_positive = f1_score(y_true, y_pred, pos_label=1)\n",
        "    average_accuracy = (accuracy_score(y_true, y_pred) +\n",
        "                        accuracy_score(y_true, y_pred, normalize=False)) / 2\n",
        "    overall_accuracy = accuracy_score(y_true, y_pred)\n",
        "    gmean = geometric_mean_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred)\n",
        "    print(\"True Negative (TN):\", tn)\n",
        "    print(\"False Positive (FP):\", fp)\n",
        "    print(\"False Negative (FN):\", fn)\n",
        "    print(\"True Positive (TP):\", tp)\n",
        "    print(\"Precision (Negative Class):\", precision_negative)\n",
        "    print(\"Recall (Negative Class):\", recall_negative)\n",
        "    print(\"F-score (Negative Class):\", fscore_negative)\n",
        "    print(\"Precision (Positive Class):\", precision_positive)\n",
        "    print(\"Recall (Positive Class):\", recall_positive)\n",
        "    print(\"F-score (Positive Class):\", fscore_positive)\n",
        "    print(\"Average Accuracy:\", average_accuracy)\n",
        "    print(\"Overall Accuracy:\", overall_accuracy)\n",
        "    print(\"G-Mean:\", gmean)\n",
        "    print(\"AUC (Area Under the Curve):\", roc_auc)\n",
        "    print(\"\\n\")\n",
        "\n",
        "def save_csv(model_name, dataset_name, param, y_true, y_pred):\n",
        "  file_name = 'risultati_modelli.xlsx'\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  tn, fp, fn, tp = cm.ravel()\n",
        "  precision_negative = precision_score(y_true, y_pred, pos_label=0)\n",
        "  recall_negative = recall_score(y_true, y_pred, pos_label=0)\n",
        "  fscore_negative = f1_score(y_true, y_pred, pos_label=0)\n",
        "  precision_positive = precision_score(y_true, y_pred, pos_label=1)\n",
        "  recall_positive = recall_score(y_true, y_pred, pos_label=1)\n",
        "  fscore_positive = f1_score(y_true, y_pred, pos_label=1)\n",
        "  average_accuracy = (accuracy_score(y_true, y_pred) +\n",
        "                      accuracy_score(y_true, y_pred, normalize=False)) / 2\n",
        "  overall_accuracy = accuracy_score(y_true, y_pred)\n",
        "  gmean = geometric_mean_score(y_true, y_pred)\n",
        "  roc_auc = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "  results = [\n",
        "      {\n",
        "          'Modello': model_name,\n",
        "          'Dataset': dataset_name,\n",
        "          'Parametri della configurazione': param,\n",
        "          'True Negative': tn,\n",
        "          'False Negative': fn,\n",
        "          'False Positive': fp,\n",
        "          'True Positive': tp,\n",
        "          'Precision Negative': precision_negative,\n",
        "          'Recall Negative': recall_negative,\n",
        "          'Fscore Negative': fscore_negative,\n",
        "          'Precision Positive': precision_positive,\n",
        "          'Recall Positive': recall_positive,\n",
        "          'Fscore Positive': fscore_positive,\n",
        "          'Average Accuracy': average_accuracy,\n",
        "          'Overall Accuracy': overall_accuracy,\n",
        "          'GMean': gmean,\n",
        "          'AUC': roc_auc,\n",
        "      },\n",
        "  ]\n",
        "\n",
        "  if os.path.exists(file_name):\n",
        "      existing_df = pd.read_excel(file_name)\n",
        "      df = pd.concat([existing_df, pd.DataFrame(results)])\n",
        "  else:\n",
        "      df = pd.DataFrame(results)\n",
        "  wb = Workbook()\n",
        "  ws = wb.active\n",
        "  for r in dataframe_to_rows(df, index=False, header=True):\n",
        "      ws.append(r)\n",
        "  wb.save(file_name)"
      ],
      "metadata": {
        "id": "JnvN2_VlDWT9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = 'Immagini_satellitari/Train'\n",
        "test_path = 'Immagini_satellitari/Test/'\n",
        "model_name = \"rf_split100_GridSearch_model.h\"\n",
        "param = 'rf split100 GridSearch'\n",
        "param_grid = {\n",
        "    \"class_weight\": [{0: 1, 1: 1}, {0: 1, 1: 2}, {0: 1, 1: 3}, {0: 1, 1: 4}, {0: 1, 1: 5}, \"balanced\"],\n",
        "    \"max_depth\": [7, 8, 9],\n",
        "    \"max_samples\": [0.8, 0.9, 1.0],\n",
        "    \"criterion\": [\"entropy\", \"gini\", \"gini\"],\n",
        "    \"max_features\": [\"sqrt\", \"log2\"]\n",
        "}\n",
        "\n",
        "trainX,trainY = loaddataset(train_path)\n",
        "testX,testY = loaddataset(test_path)\n",
        "\n",
        "X1,Y1 = selectSet(trainX, trainY, 1)\n",
        "X0,Y0 = selectSet(trainX, trainY, 0)\n",
        "X1,Y1 = sampling(X1, Y1, 1000)\n",
        "X0,Y0 = sampling(X0, Y0, 1000)\n",
        "X,Y = concatenate(X1, X0, Y1, Y0)\n",
        "grindsearch(param_grid,X,Y,model_name)\n",
        "\n",
        "test_predictions = rftest(testX,model_name)\n",
        "print(\"TEST : \")\n",
        "print_metrics(testY,test_predictions)\n",
        "save_csv(model_name, 'Test Set', param, testY, test_predictions)\n",
        "\n",
        "train_predictions = rftest(trainX,model_name)\n",
        "print(\"TRAIN : \")\n",
        "print_metrics(trainY,train_predictions)\n",
        "save_csv(model_name, 'Train Set', param, trainY, train_predictions)\n",
        "\n",
        "sample_predictions = rftest(X,model_name)\n",
        "print(\"Sample TRAIN : \")\n",
        "print_metrics(Y,sample_predictions)\n",
        "save_csv(model_name, 'Sample Set', param, Y, sample_predictions)"
      ],
      "metadata": {
        "id": "DxdmzMQ_ergz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34284e58-f7cf-4da5-f9ba-7fd5acd4b77c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST : \n",
            "True Negative (TN): 86236\n",
            "False Positive (FP): 75864\n",
            "False Negative (FN): 1701\n",
            "True Positive (TP): 1063\n",
            "Precision (Negative Class): 0.9806566064341518\n",
            "Recall (Negative Class): 0.5319925971622456\n",
            "F-score (Negative Class): 0.6897859116850706\n",
            "Precision (Positive Class): 0.013818295266941385\n",
            "Recall (Positive Class): 0.3845875542691751\n",
            "F-score (Positive Class): 0.026678043944736544\n",
            "Average Accuracy: 43649.764760651204\n",
            "Overall Accuracy: 0.5295213024068323\n",
            "G-Mean: 0.4523248078891257\n",
            "AUC (Area Under the Curve): 0.4582900757157103\n",
            "\n",
            "\n",
            "TRAIN : \n",
            "True Negative (TN): 343982\n",
            "False Positive (FP): 302183\n",
            "False Negative (FN): 9140\n",
            "True Positive (TP): 14391\n",
            "Precision (Negative Class): 0.9741165942648716\n",
            "Recall (Negative Class): 0.5323439059682898\n",
            "F-score (Negative Class): 0.688454868321113\n",
            "Precision (Positive Class): 0.04545856576977263\n",
            "Recall (Positive Class): 0.6115762186052441\n",
            "F-score (Positive Class): 0.08462680642742683\n",
            "Average Accuracy: 179186.76756393947\n",
            "Overall Accuracy: 0.5351278789181957\n",
            "G-Mean: 0.5705864290443933\n",
            "AUC (Area Under the Curve): 0.571960062286767\n",
            "\n",
            "\n",
            "Sample TRAIN : \n",
            "True Negative (TN): 817\n",
            "False Positive (FP): 183\n",
            "False Negative (FN): 160\n",
            "True Positive (TP): 840\n",
            "Precision (Negative Class): 0.8362333674513818\n",
            "Recall (Negative Class): 0.817\n",
            "F-score (Negative Class): 0.8265048052604956\n",
            "Precision (Positive Class): 0.8211143695014663\n",
            "Recall (Positive Class): 0.84\n",
            "F-score (Positive Class): 0.8304498269896193\n",
            "Average Accuracy: 828.91425\n",
            "Overall Accuracy: 0.8285\n",
            "G-Mean: 0.828420183240365\n",
            "AUC (Area Under the Curve): 0.8284999999999999\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}