{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOFNFmi41ESE4iq6nHGL5D9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucevito/image/blob/main/random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6cm4yTyDP7C",
        "outputId": "38b4a9a7-457a-4bb8-c5b3-670e3e5eae30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'drive/MyDrive'\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import joblib\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "import os\n",
        "import pandas as pd\n",
        "from openpyxl import Workbook, load_workbook\n",
        "from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "\n",
        "\n",
        "def loaddataset(directory):\n",
        "  images_files = glob.glob(directory + '/images' + '/*.npy')\n",
        "  masks_files = glob.glob(directory + '/masks' + '/*.npy')\n",
        "  x = np.array([np.load(file) for file in images_files])\n",
        "  y = np.array([np.load(file) for file in masks_files])\n",
        "  x = x.reshape(len(x) * len(x[0]) * len(x[0][0]), 10)\n",
        "  y = y.reshape(len(y) * len(y[0]) * len(y[0][0]), 1)\n",
        "  y = np.ravel(y)\n",
        "  return x,y\n",
        "\n",
        "def rflearn(X,Y,filename):\n",
        "  rf_model = RandomForestClassifier(random_state=42)\n",
        "  rf_model.fit(X, Y)\n",
        "  joblib.dump(rf_model, filename)\n",
        "\n",
        "def rftest(test,filename):\n",
        "  rf_model = joblib.load(filename)\n",
        "  predictions = rf_model.predict(test)\n",
        "  return predictions\n",
        "\n",
        "\n",
        "def print_metrics(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    precision_negative = precision_score(y_true, y_pred, pos_label=0)\n",
        "    recall_negative = recall_score(y_true, y_pred, pos_label=0)\n",
        "    fscore_negative = f1_score(y_true, y_pred, pos_label=0)\n",
        "    precision_positive = precision_score(y_true, y_pred, pos_label=1)\n",
        "    recall_positive = recall_score(y_true, y_pred, pos_label=1)\n",
        "    fscore_positive = f1_score(y_true, y_pred, pos_label=1)\n",
        "    average_accuracy = (accuracy_score(y_true, y_pred) +\n",
        "                        accuracy_score(y_true, y_pred, normalize=False)) / 2\n",
        "    overall_accuracy = accuracy_score(y_true, y_pred)\n",
        "    gmean = geometric_mean_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred)\n",
        "    print(\"True Negative (TN):\", tn)\n",
        "    print(\"False Negative (FN):\", fn)\n",
        "    print(\"False Positive (FP):\", fp)\n",
        "    print(\"True Positive (TP):\", tp)\n",
        "    print(\"Precision (Negative Class):\", precision_negative)\n",
        "    print(\"Recall (Negative Class):\", recall_negative)\n",
        "    print(\"F-score (Negative Class):\", fscore_negative)\n",
        "    print(\"Precision (Positive Class):\", precision_positive)\n",
        "    print(\"Recall (Positive Class):\", recall_positive)\n",
        "    print(\"F-score (Positive Class):\", fscore_positive)\n",
        "    print(\"Average Accuracy:\", average_accuracy)\n",
        "    print(\"Overall Accuracy:\", overall_accuracy)\n",
        "    print(\"G-Mean:\", gmean)\n",
        "    print(\"AUC (Area Under the Curve):\", roc_auc)\n",
        "    print(\"\\n\")\n",
        "\n",
        "def save_csv(model_name, dataset_name, param, y_true, y_pred):\n",
        "  file_name = 'risultati_modelli.xlsx'\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  tn, fp, fn, tp = cm.ravel()\n",
        "  precision_negative = precision_score(y_true, y_pred, pos_label=0)\n",
        "  recall_negative = recall_score(y_true, y_pred, pos_label=0)\n",
        "  fscore_negative = f1_score(y_true, y_pred, pos_label=0)\n",
        "  precision_positive = precision_score(y_true, y_pred, pos_label=1)\n",
        "  recall_positive = recall_score(y_true, y_pred, pos_label=1)\n",
        "  fscore_positive = f1_score(y_true, y_pred, pos_label=1)\n",
        "  average_accuracy = (accuracy_score(y_true, y_pred) +\n",
        "                      accuracy_score(y_true, y_pred, normalize=False)) / 2\n",
        "  overall_accuracy = accuracy_score(y_true, y_pred)\n",
        "  gmean = geometric_mean_score(y_true, y_pred)\n",
        "  roc_auc = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "  results = [\n",
        "      {\n",
        "          'Modello': model_name,\n",
        "          'Dataset': dataset_name,\n",
        "          'Parametri della configurazione': param,\n",
        "          'True Negative': tn,\n",
        "          'False Negative': fn,\n",
        "          'False Positive': fp,\n",
        "          'True Positive': tp,\n",
        "          'Precision Negative': precision_negative,\n",
        "          'Recall Negative': recall_negative,\n",
        "          'Fscore Negative': fscore_negative,\n",
        "          'Precision Positive': precision_positive,\n",
        "          'Recall Positive': recall_positive,\n",
        "          'Fscore Positive': fscore_positive,\n",
        "          'Average Accuracy': average_accuracy,\n",
        "          'Overall Accuracy': overall_accuracy,\n",
        "          'GMean': gmean,\n",
        "          'AUC': roc_auc,\n",
        "      },\n",
        "  ]\n",
        "\n",
        "  if os.path.exists(file_name):\n",
        "      existing_df = pd.read_excel(file_name)\n",
        "      df = pd.concat([existing_df, pd.DataFrame(results)])\n",
        "  else:\n",
        "      df = pd.DataFrame(results)\n",
        "  wb = Workbook()\n",
        "  ws = wb.active\n",
        "  for r in dataframe_to_rows(df, index=False, header=True):\n",
        "      ws.append(r)\n",
        "  wb.save(file_name)"
      ],
      "metadata": {
        "id": "JnvN2_VlDWT9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = 'Immagini_satellitari/Train'\n",
        "test_path = 'Immagini_satellitari/Test/'\n",
        "model_name = \"rf_model.h\"\n",
        "param = 'rf senza bilanciamenti'\n",
        "\n",
        "trainX,trainY = loaddataset(train_path)\n",
        "testX,testY = loaddataset(test_path)\n",
        "\n",
        "rflearn(trainX,trainY,model_name)\n",
        "\n",
        "test_predictions = rftest(testX,model_name)\n",
        "print(\"TEST : \")\n",
        "print_metrics(testY,test_predictions)\n",
        "save_csv(model_name, 'Test Set', param, testY, test_predictions)\n",
        "\n",
        "train_predictions = rftest(trainX,model_name)\n",
        "print(\"TRAIN : \")\n",
        "print_metrics(trainY,train_predictions)\n",
        "save_csv(model_name, 'Train Set', param, trainY, train_predictions)"
      ],
      "metadata": {
        "id": "DxdmzMQ_ergz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69121467-6124-4151-a907-e9d0e1aa0b15"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST : \n",
            "True Negative (TN): 161888\n",
            "False Negative (FN): 2753\n",
            "False Positive (FP): 212\n",
            "True Positive (TP): 11\n",
            "Precision (Negative Class): 0.9832787701726787\n",
            "Recall (Negative Class): 0.9986921653300432\n",
            "F-score (Negative Class): 0.9909255342916867\n",
            "Precision (Positive Class): 0.04932735426008968\n",
            "Recall (Positive Class): 0.003979739507959479\n",
            "F-score (Positive Class): 0.007365249414127887\n",
            "Average Accuracy: 80949.9910077397\n",
            "Overall Accuracy: 0.9820154794254659\n",
            "G-Mean: 0.06304391062310118\n",
            "AUC (Area Under the Curve): 0.5013359524190014\n",
            "\n",
            "\n",
            "TRAIN : \n",
            "True Negative (TN): 646037\n",
            "False Negative (FN): 645\n",
            "False Positive (FP): 128\n",
            "True Positive (TP): 22886\n",
            "Precision (Negative Class): 0.9990026009692554\n",
            "Recall (Negative Class): 0.9998019081813468\n",
            "F-score (Negative Class): 0.9994020947567654\n",
            "Precision (Positive Class): 0.9944381680716086\n",
            "Recall (Positive Class): 0.9725893502188603\n",
            "F-score (Positive Class): 0.9833924159415619\n",
            "Average Accuracy: 334461.99942287244\n",
            "Overall Accuracy: 0.9988457449350153\n",
            "G-Mean: 0.9861017636256781\n",
            "AUC (Area Under the Curve): 0.9861956292001036\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}