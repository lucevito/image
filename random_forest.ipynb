{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMhmCUgmo9noWTrgPxkZZs3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucevito/image/blob/main/random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6cm4yTyDP7C",
        "outputId": "527542d1-4aef-4be1-b7c9-23a684354b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import joblib\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "import os\n",
        "import pandas as pd\n",
        "from openpyxl import Workbook, load_workbook\n",
        "from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "\n",
        "\n",
        "def loaddataset(directory):\n",
        "  images_files = glob.glob(directory + '/images' + '/*.npy')\n",
        "  masks_files = glob.glob(directory + '/masks' + '/*.npy')\n",
        "  x = np.array([np.load(file) for file in images_files])\n",
        "  y = np.array([np.load(file) for file in masks_files])\n",
        "  x = x.reshape(len(x) * len(x[0]) * len(x[0][0]), 10)\n",
        "  y = y.reshape(len(y) * len(y[0]) * len(y[0][0]), 1)\n",
        "  y = np.ravel(y)\n",
        "  return x,y\n",
        "\n",
        "def rflearn(X,Y,filename):\n",
        "  rf_model = RandomForestClassifier(random_state=42)\n",
        "  rf_model.fit(X, Y)\n",
        "  joblib.dump(rf_model, filename)\n",
        "\n",
        "def rftest(test,filename):\n",
        "  rf_model = joblib.load(filename)\n",
        "  predictions = rf_model.predict(test)\n",
        "  return predictions\n",
        "\n",
        "\n",
        "def print_metrics(y_true, y_pred):\n",
        "    # Calcola la matrice di confusione\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    # Metriche per la classe negativa (classe 0)\n",
        "    precision_negative = precision_score(y_true, y_pred, pos_label=0)\n",
        "    recall_negative = recall_score(y_true, y_pred, pos_label=0)\n",
        "    fscore_negative = f1_score(y_true, y_pred, pos_label=0)\n",
        "    # Metriche per la classe positiva (classe 1)\n",
        "    precision_positive = precision_score(y_true, y_pred, pos_label=1)\n",
        "    recall_positive = recall_score(y_true, y_pred, pos_label=1)\n",
        "    fscore_positive = f1_score(y_true, y_pred, pos_label=1)\n",
        "    # Calcola l'accuratezza media e l'accuratezza complessiva\n",
        "    average_accuracy = (accuracy_score(y_true, y_pred) + accuracy_score(y_true, y_pred, normalize=False)) / 2\n",
        "    overall_accuracy = accuracy_score(y_true, y_pred)\n",
        "    # Calcola la G-Mean (Geometric Mean Score)\n",
        "    gmean = geometric_mean_score(y_true, y_pred)\n",
        "    # Calcola l'AUC (Area Under the Curve) per la curva ROC\n",
        "    roc_auc = roc_auc_score(y_true, y_pred)\n",
        "    print(\"True Negative (TN):\", tn)\n",
        "    print(\"False Positive (FP):\", fp)\n",
        "    print(\"False Negative (FN):\", fn)\n",
        "    print(\"True Positive (TP):\", tp)\n",
        "    print(\"Precision (Negative Class):\", precision_negative)\n",
        "    print(\"Recall (Negative Class):\", recall_negative)\n",
        "    print(\"F-score (Negative Class):\", fscore_negative)\n",
        "    print(\"Precision (Positive Class):\", precision_positive)\n",
        "    print(\"Recall (Positive Class):\", recall_positive)\n",
        "    print(\"F-score (Positive Class):\", fscore_positive)\n",
        "    print(\"Average Accuracy:\", average_accuracy)\n",
        "    print(\"Overall Accuracy:\", overall_accuracy)\n",
        "    print(\"G-Mean:\", gmean)\n",
        "    print(\"AUC (Area Under the Curve):\", roc_auc)\n",
        "    print(\"\\n\")\n",
        "\n",
        "def save_csv(model_name,y_true_train, y_pred_train,y_true_test,y_pred_test):\n",
        "\n",
        "  file_name = 'risultati_modelli.xlsx'\n",
        "  cm_train = confusion_matrix(y_true_train, y_pred_train)\n",
        "  tn_train, fp_train, fn_train, tp_train = cm_train.ravel()\n",
        "  precision_negative_train = precision_score(y_true_train, y_pred_train, pos_label=0)\n",
        "  recall_negative_train = recall_score(y_true_train, y_pred_train, pos_label=0)\n",
        "  fscore_negative_train = f1_score(y_true_train, y_pred_train, pos_label=0)\n",
        "  precision_positive_train = precision_score(y_true_train, y_pred_train, pos_label=1)\n",
        "  recall_positive_train = recall_score(y_true_train, y_pred_train, pos_label=1)\n",
        "  fscore_positive_train = f1_score(y_true_train, y_pred_train, pos_label=1)\n",
        "  average_accuracy_train = (accuracy_score(y_true_train, y_pred_train) + accuracy_score(y_true_train, y_pred_train, normalize=False)) / 2\n",
        "  overall_accuracy_train = accuracy_score(y_true_train, y_pred_train)\n",
        "  gmean_train = geometric_mean_score(y_true_train, y_pred_train)\n",
        "  roc_auc_train = roc_auc_score(y_true_train, y_pred_train)\n",
        "\n",
        "  cm_test = confusion_matrix(y_true_test, y_pred_test)\n",
        "  tn_test, fp_test, fn_test, tp_test = cm_test.ravel()\n",
        "  precision_negative_test = precision_score(y_true_test, y_pred_test, pos_label=0)\n",
        "  recall_negative_test = recall_score(y_true_test, y_pred_test, pos_label=0)\n",
        "  fscore_negative_test = f1_score(y_true_test, y_pred_test, pos_label=0)\n",
        "  precision_positive_test = precision_score(y_true_test, y_pred_test, pos_label=1)\n",
        "  recall_positive_test = recall_score(y_true_test, y_pred_test, pos_label=1)\n",
        "  fscore_positive_test = f1_score(y_true_test, y_pred_test, pos_label=1)\n",
        "  average_accuracy_test = (accuracy_score(y_true_test, y_pred_test) + accuracy_score(y_true_test, y_pred_test, normalize=False)) / 2\n",
        "  overall_accuracy_test = accuracy_score(y_true_test, y_pred_test)\n",
        "  gmean_test = geometric_mean_score(y_true_test, y_pred_test)\n",
        "  roc_auc_test = roc_auc_score(y_true_test, y_pred_test)\n",
        "\n",
        "  results = [\n",
        "      {\n",
        "          'Modello': model_name,\n",
        "          'Dataset': 'Train Set',\n",
        "          'Parametri della configurazione': 'rf_senza_bilanciamenti',\n",
        "          'True Negative': tn_train,\n",
        "          'False Negative': fn_train,\n",
        "          'False Positive': fp_train,\n",
        "          'True Positive': tp_train,\n",
        "          'Precision Negative': precision_negative_train,\n",
        "          'Recall Negative': recall_negative_train,\n",
        "          'Fscore Negative': fscore_negative_train,\n",
        "          'Precision Positive': precision_positive_train,\n",
        "          'Recall Positive': recall_positive_train,\n",
        "          'Fscore Positive': fscore_positive_train,\n",
        "          'Average Accuracy': average_accuracy_train,\n",
        "          'Overall Accuracy': overall_accuracy_train,\n",
        "          'GMean': gmean_train,\n",
        "          'AUC': roc_auc_train,\n",
        "      },\n",
        "      {\n",
        "          'Modello': model_name,\n",
        "          'Dataset': 'Test Set',\n",
        "          'Parametri della configurazione': 'rf_senza_bilanciamenti',\n",
        "          'True Negative': tn_test,\n",
        "          'False Negative': fn_test,\n",
        "          'False Positive': fp_test,\n",
        "          'True Positive': tp_test,\n",
        "          'Precision Negative': precision_negative_test,\n",
        "          'Recall Negative': recall_negative_test,\n",
        "          'Fscore Negative': fscore_negative_test,\n",
        "          'Precision Positive': precision_positive_test,\n",
        "          'Recall Positive': recall_positive_test,\n",
        "          'Fscore Positive': fscore_positive_test,\n",
        "          'Average Accuracy': average_accuracy_test,\n",
        "          'Overall Accuracy': overall_accuracy_test,\n",
        "          'GMean': gmean_test,\n",
        "          'AUC': roc_auc_test,\n",
        "      },\n",
        "  ]\n",
        "\n",
        "  # Controlla se il file del foglio di calcolo esiste\n",
        "  if os.path.exists(file_name):\n",
        "      # Carica i dati esistenti dal foglio di calcolo\n",
        "      existing_df = pd.read_excel(file_name)\n",
        "      # Unisci i nuovi dati con quelli esistenti\n",
        "      df = pd.concat([existing_df, pd.DataFrame(results)])\n",
        "  else:\n",
        "      # Se il file non esiste, crea semplicemente il DataFrame con i nuovi dati\n",
        "      df = pd.DataFrame(results)\n",
        "\n",
        "  # Creazione del foglio di calcolo Excel\n",
        "  wb = Workbook()\n",
        "  ws = wb.active\n",
        "\n",
        "  # Inserimento dei dati nel foglio di calcolo\n",
        "  for r in dataframe_to_rows(df, index=False, header=True):\n",
        "      ws.append(r)\n",
        "\n",
        "  # Salvataggio del foglio di calcolo\n",
        "  wb.save(file_name)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JnvN2_VlDWT9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = 'Immagini_satellitari/Train'\n",
        "test_path = 'Immagini_satellitari/Test/'\n",
        "model_name = \"rf_model.h\"\n",
        "\n",
        "trainX,trainY = loaddataset(train_path)\n",
        "testX,testY = loaddataset(test_path)\n",
        "\n",
        "rflearn(trainX,trainY,model_name)\n",
        "\n",
        "\n",
        "test_predictions = rftest(testX,model_name)\n",
        "print(\"TEST : \")\n",
        "print_metrics(testY,test_predictions)\n",
        "\n",
        "train_predictions = rftest(trainX,model_name)\n",
        "print(\"TRAIN : \")\n",
        "print_metrics(trainY,train_predictions)\n",
        "\n",
        "save_csv(model_name,trainY, train_predictions,testY,test_predictions)\n"
      ],
      "metadata": {
        "id": "DxdmzMQ_ergz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "678a92a0-7084-467d-b858-0c555d289b1f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST : \n",
            "True Negative (TN): 161888\n",
            "False Positive (FP): 212\n",
            "False Negative (FN): 2753\n",
            "True Positive (TP): 11\n",
            "Precision (Negative Class): 0.9832787701726787\n",
            "Recall (Negative Class): 0.9986921653300432\n",
            "F-score (Negative Class): 0.9909255342916867\n",
            "Precision (Positive Class): 0.04932735426008968\n",
            "Recall (Positive Class): 0.003979739507959479\n",
            "F-score (Positive Class): 0.007365249414127887\n",
            "Average Accuracy: 80949.9910077397\n",
            "Overall Accuracy: 0.9820154794254659\n",
            "G-Mean: 0.06304391062310118\n",
            "AUC (Area Under the Curve): 0.5013359524190014\n",
            "\n",
            "\n",
            "TRAIN : \n",
            "True Negative (TN): 646037\n",
            "False Positive (FP): 128\n",
            "False Negative (FN): 645\n",
            "True Positive (TP): 22886\n",
            "Precision (Negative Class): 0.9990026009692554\n",
            "Recall (Negative Class): 0.9998019081813468\n",
            "F-score (Negative Class): 0.9994020947567654\n",
            "Precision (Positive Class): 0.9944381680716086\n",
            "Recall (Positive Class): 0.9725893502188603\n",
            "F-score (Positive Class): 0.9833924159415619\n",
            "Average Accuracy: 334461.99942287244\n",
            "Overall Accuracy: 0.9988457449350153\n",
            "G-Mean: 0.9861017636256781\n",
            "AUC (Area Under the Curve): 0.9861956292001036\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}