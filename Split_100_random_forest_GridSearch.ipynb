{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNfe6l5rm6JeFBn4jAt0usA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucevito/image/blob/main/Split_100_random_forest_GridSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6cm4yTyDP7C",
        "outputId": "0a56c972-3aeb-473a-9a72-83e8584cded8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "import joblib\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "import os\n",
        "import pandas as pd\n",
        "from openpyxl import Workbook, load_workbook\n",
        "from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "\n",
        "\n",
        "def loaddataset(directory):\n",
        "  images_files = glob.glob(directory + '/images' + '/*.npy')\n",
        "  masks_files = glob.glob(directory + '/masks' + '/*.npy')\n",
        "  x = np.array([np.load(file) for file in images_files])\n",
        "  y = np.array([np.load(file) for file in masks_files])\n",
        "  x = x.reshape(len(x) * len(x[0]) * len(x[0][0]), 10)\n",
        "  y = y.reshape(len(y) * len(y[0]) * len(y[0][0]), 1)\n",
        "  y = np.ravel(y)\n",
        "  return x,y\n",
        "\n",
        "def rflearn(X,Y,filename):\n",
        "  rf_model = RandomForestClassifier(random_state=42)\n",
        "  rf_model.fit(X, Y)\n",
        "  joblib.dump(rf_model, filename)\n",
        "\n",
        "def rftest(test,filename):\n",
        "  rf_model = joblib.load(filename)\n",
        "  predictions = rf_model.predict(test)\n",
        "  return predictions\n",
        "\n",
        "def grindsearch(param_grid,X,Y,filename):\n",
        "  rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "  grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='roc_auc')\n",
        "  grid_search.fit(X, Y)\n",
        "\n",
        "  best_params = grid_search.best_params_\n",
        "  best_score = grid_search.best_score_\n",
        "\n",
        "  best_rf_model = RandomForestClassifier(**best_params, random_state=42)\n",
        "  best_rf_model.fit(X, Y)\n",
        "  joblib.dump(rf_model, filename)\n",
        "\n",
        "def selectSet(X, Y, target_class):\n",
        "  mask = (Y == target_class)\n",
        "  selectionX = X[mask]\n",
        "  selectionY = Y[mask]\n",
        "  return selectionX, selectionY\n",
        "\n",
        "def sampling(X, Y, n):\n",
        "    indices = np.random.choice(len(X), n, replace=False)\n",
        "    sampleX = X[indices]\n",
        "    sampleY = Y[indices]\n",
        "    return sampleX, sampleY\n",
        "\n",
        "def concatenate(X1, X2, Y1, Y2):\n",
        "    X = np.concatenate((X1, X2), axis=0)\n",
        "    Y = np.concatenate((Y1, Y2), axis=0)\n",
        "    return X, Y\n",
        "\n",
        "def print_metrics(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    precision_negative = precision_score(y_true, y_pred, pos_label=0)\n",
        "    recall_negative = recall_score(y_true, y_pred, pos_label=0)\n",
        "    fscore_negative = f1_score(y_true, y_pred, pos_label=0)\n",
        "    precision_positive = precision_score(y_true, y_pred, pos_label=1)\n",
        "    recall_positive = recall_score(y_true, y_pred, pos_label=1)\n",
        "    fscore_positive = f1_score(y_true, y_pred, pos_label=1)\n",
        "    average_accuracy = (accuracy_score(y_true, y_pred) +\n",
        "                        accuracy_score(y_true, y_pred, normalize=False)) / 2\n",
        "    overall_accuracy = accuracy_score(y_true, y_pred)\n",
        "    gmean = geometric_mean_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred)\n",
        "    print(\"True Negative (TN):\", tn)\n",
        "    print(\"False Positive (FP):\", fp)\n",
        "    print(\"False Negative (FN):\", fn)\n",
        "    print(\"True Positive (TP):\", tp)\n",
        "    print(\"Precision (Negative Class):\", precision_negative)\n",
        "    print(\"Recall (Negative Class):\", recall_negative)\n",
        "    print(\"F-score (Negative Class):\", fscore_negative)\n",
        "    print(\"Precision (Positive Class):\", precision_positive)\n",
        "    print(\"Recall (Positive Class):\", recall_positive)\n",
        "    print(\"F-score (Positive Class):\", fscore_positive)\n",
        "    print(\"Average Accuracy:\", average_accuracy)\n",
        "    print(\"Overall Accuracy:\", overall_accuracy)\n",
        "    print(\"G-Mean:\", gmean)\n",
        "    print(\"AUC (Area Under the Curve):\", roc_auc)\n",
        "    print(\"\\n\")\n",
        "\n",
        "def save_csv(model_name, dataset_name, param, y_true, y_pred):\n",
        "  file_name = 'risultati_modelli.xlsx'\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  tn, fp, fn, tp = cm.ravel()\n",
        "  precision_negative = precision_score(y_true, y_pred, pos_label=0)\n",
        "  recall_negative = recall_score(y_true, y_pred, pos_label=0)\n",
        "  fscore_negative = f1_score(y_true, y_pred, pos_label=0)\n",
        "  precision_positive = precision_score(y_true, y_pred, pos_label=1)\n",
        "  recall_positive = recall_score(y_true, y_pred, pos_label=1)\n",
        "  fscore_positive = f1_score(y_true, y_pred, pos_label=1)\n",
        "  average_accuracy = (accuracy_score(y_true, y_pred) +\n",
        "                      accuracy_score(y_true, y_pred, normalize=False)) / 2\n",
        "  overall_accuracy = accuracy_score(y_true, y_pred)\n",
        "  gmean = geometric_mean_score(y_true, y_pred)\n",
        "  roc_auc = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "  results = [\n",
        "      {\n",
        "          'Modello': model_name,\n",
        "          'Dataset': dataset_name,\n",
        "          'Parametri della configurazione': param,\n",
        "          'True Negative': tn,\n",
        "          'False Negative': fn,\n",
        "          'False Positive': fp,\n",
        "          'True Positive': tp,\n",
        "          'Precision Negative': precision_negative,\n",
        "          'Recall Negative': recall_negative,\n",
        "          'Fscore Negative': fscore_negative,\n",
        "          'Precision Positive': precision_positive,\n",
        "          'Recall Positive': recall_positive,\n",
        "          'Fscore Positive': fscore_positive,\n",
        "          'Average Accuracy': average_accuracy,\n",
        "          'Overall Accuracy': overall_accuracy,\n",
        "          'GMean': gmean,\n",
        "          'AUC': roc_auc,\n",
        "      },\n",
        "  ]\n",
        "\n",
        "  if os.path.exists(file_name):\n",
        "      existing_df = pd.read_excel(file_name)\n",
        "      df = pd.concat([existing_df, pd.DataFrame(results)])\n",
        "  else:\n",
        "      df = pd.DataFrame(results)\n",
        "  wb = Workbook()\n",
        "  ws = wb.active\n",
        "  for r in dataframe_to_rows(df, index=False, header=True):\n",
        "      ws.append(r)\n",
        "  wb.save(file_name)"
      ],
      "metadata": {
        "id": "JnvN2_VlDWT9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = 'Immagini_satellitari/Train'\n",
        "test_path = 'Immagini_satellitari/Test/'\n",
        "model_name = \"rf_split100_GridSearch_model.h\"\n",
        "param = 'rf split100 GridSearch'\n",
        "param_grid = {\n",
        "    \"class_weight\": [{0: 1, 1: 1}, {0: 1, 1: 2}, {0: 1, 1: 3}, {0: 1, 1: 4}, {0: 1, 1: 5}, \"balanced\"],\n",
        "    \"max_depth\": [7, 8, 9],\n",
        "    \"max_samples\": [0.8, 0.9, 1.0],\n",
        "    \"criterion\": [\"entropy\", \"gini\", \"gini\"],\n",
        "    \"max_features\": [\"sqrt\", \"log2\"]\n",
        "}\n",
        "\n",
        "trainX,trainY = loaddataset(train_path)\n",
        "testX,testY = loaddataset(test_path)\n",
        "\n",
        "X1,Y1 = selectSet(trainX, trainY, 1)\n",
        "X0,Y0 = selectSet(trainX, trainY, 0)\n",
        "X1,Y1 = sampling(X1, Y1, 100)\n",
        "X0,Y0 = sampling(X0, Y0, 100)\n",
        "X,Y = concatenate(X1, X0, Y1, Y0)\n",
        "grindsearch(param_grid,X,Y,model_name)\n",
        "\n",
        "test_predictions = rftest(testX,model_name)\n",
        "print(\"TEST : \")\n",
        "print_metrics(testY,test_predictions)\n",
        "save_csv(model_name, 'Test Set', param, testY, test_predictions)\n",
        "\n",
        "train_predictions = rftest(trainX,model_name)\n",
        "print(\"TRAIN : \")\n",
        "print_metrics(trainY,train_predictions)\n",
        "save_csv(model_name, 'Train Set', param, trainY, train_predictions)"
      ],
      "metadata": {
        "id": "DxdmzMQ_ergz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}