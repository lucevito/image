{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMgbkh1nbDAkXdrMKi7SVSP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucevito/image/blob/main/Split_len(X1)_random_forest_GridSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6cm4yTyDP7C",
        "outputId": "4fec732c-3cf6-4b81-b67f-be74798c06fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'drive/MyDrive'\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "import joblib\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "import os\n",
        "import pandas as pd\n",
        "from openpyxl import Workbook, load_workbook\n",
        "from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "\n",
        "\n",
        "def loaddataset(directory):\n",
        "  images_files = glob.glob(directory + '/images' + '/*.npy')\n",
        "  masks_files = glob.glob(directory + '/masks' + '/*.npy')\n",
        "  x = np.array([np.load(file) for file in images_files])\n",
        "  y = np.array([np.load(file) for file in masks_files])\n",
        "  x = x.reshape(len(x) * len(x[0]) * len(x[0][0]), 10)\n",
        "  y = y.reshape(len(y) * len(y[0]) * len(y[0][0]), 1)\n",
        "  y = np.ravel(y)\n",
        "  return x,y\n",
        "\n",
        "def rflearn(X,Y,filename):\n",
        "  rf_model = RandomForestClassifier(random_state=42)\n",
        "  rf_model.fit(X, Y)\n",
        "  joblib.dump(rf_model, filename)\n",
        "\n",
        "def rftest(test,filename):\n",
        "  rf_model = joblib.load(filename)\n",
        "  predictions = rf_model.predict(test)\n",
        "  return predictions\n",
        "\n",
        "def grindsearch(param_grid,X,Y,filename):\n",
        "  rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "  grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='roc_auc')\n",
        "  grid_search.fit(X, Y)\n",
        "\n",
        "  best_params = grid_search.best_params_\n",
        "  best_score = grid_search.best_score_\n",
        "\n",
        "  best_rf_model = RandomForestClassifier(**best_params, random_state=42)\n",
        "  best_rf_model.fit(X, Y)\n",
        "  joblib.dump(best_rf_model, filename)\n",
        "\n",
        "def selectSet(X, Y, target_class):\n",
        "  mask = (Y == target_class)\n",
        "  selectionX = X[mask]\n",
        "  selectionY = Y[mask]\n",
        "  return selectionX, selectionY\n",
        "\n",
        "def sampling(X, Y, n):\n",
        "    indices = np.random.choice(len(X), n, replace=False)\n",
        "    sampleX = X[indices]\n",
        "    sampleY = Y[indices]\n",
        "    return sampleX, sampleY\n",
        "\n",
        "def concatenate(X1, X2, Y1, Y2):\n",
        "    X = np.concatenate((X1, X2), axis=0)\n",
        "    Y = np.concatenate((Y1, Y2), axis=0)\n",
        "    return X, Y\n",
        "\n",
        "def print_metrics(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    precision_negative = precision_score(y_true, y_pred, pos_label=0)\n",
        "    recall_negative = recall_score(y_true, y_pred, pos_label=0)\n",
        "    fscore_negative = f1_score(y_true, y_pred, pos_label=0)\n",
        "    precision_positive = precision_score(y_true, y_pred, pos_label=1)\n",
        "    recall_positive = recall_score(y_true, y_pred, pos_label=1)\n",
        "    fscore_positive = f1_score(y_true, y_pred, pos_label=1)\n",
        "    average_accuracy = (accuracy_score(y_true, y_pred) +\n",
        "                        accuracy_score(y_true, y_pred, normalize=False)) / 2\n",
        "    overall_accuracy = accuracy_score(y_true, y_pred)\n",
        "    gmean = geometric_mean_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred)\n",
        "    print(\"True Negative (TN):\", tn)\n",
        "    print(\"False Negative (FN):\", fn)\n",
        "    print(\"False Positive (FP):\", fp)\n",
        "    print(\"True Positive (TP):\", tp)\n",
        "    print(\"Precision (Negative Class):\", precision_negative)\n",
        "    print(\"Recall (Negative Class):\", recall_negative)\n",
        "    print(\"F-score (Negative Class):\", fscore_negative)\n",
        "    print(\"Precision (Positive Class):\", precision_positive)\n",
        "    print(\"Recall (Positive Class):\", recall_positive)\n",
        "    print(\"F-score (Positive Class):\", fscore_positive)\n",
        "    print(\"Average Accuracy:\", average_accuracy)\n",
        "    print(\"Overall Accuracy:\", overall_accuracy)\n",
        "    print(\"G-Mean:\", gmean)\n",
        "    print(\"AUC (Area Under the Curve):\", roc_auc)\n",
        "    print(\"\\n\")\n",
        "\n",
        "def save_csv(model_name, dataset_name, param, y_true, y_pred):\n",
        "  file_name = 'risultati_modelli.xlsx'\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  tn, fp, fn, tp = cm.ravel()\n",
        "  precision_negative = precision_score(y_true, y_pred, pos_label=0)\n",
        "  recall_negative = recall_score(y_true, y_pred, pos_label=0)\n",
        "  fscore_negative = f1_score(y_true, y_pred, pos_label=0)\n",
        "  precision_positive = precision_score(y_true, y_pred, pos_label=1)\n",
        "  recall_positive = recall_score(y_true, y_pred, pos_label=1)\n",
        "  fscore_positive = f1_score(y_true, y_pred, pos_label=1)\n",
        "  average_accuracy = (accuracy_score(y_true, y_pred) +\n",
        "                      accuracy_score(y_true, y_pred, normalize=False)) / 2\n",
        "  overall_accuracy = accuracy_score(y_true, y_pred)\n",
        "  gmean = geometric_mean_score(y_true, y_pred)\n",
        "  roc_auc = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "  results = [\n",
        "      {\n",
        "          'Modello': model_name,\n",
        "          'Dataset': dataset_name,\n",
        "          'Parametri della configurazione': param,\n",
        "          'True Negative': tn,\n",
        "          'False Negative': fn,\n",
        "          'False Positive': fp,\n",
        "          'True Positive': tp,\n",
        "          'Precision Negative': precision_negative,\n",
        "          'Recall Negative': recall_negative,\n",
        "          'Fscore Negative': fscore_negative,\n",
        "          'Precision Positive': precision_positive,\n",
        "          'Recall Positive': recall_positive,\n",
        "          'Fscore Positive': fscore_positive,\n",
        "          'Average Accuracy': average_accuracy,\n",
        "          'Overall Accuracy': overall_accuracy,\n",
        "          'GMean': gmean,\n",
        "          'AUC': roc_auc,\n",
        "      },\n",
        "  ]\n",
        "\n",
        "  if os.path.exists(file_name):\n",
        "      existing_df = pd.read_excel(file_name)\n",
        "      df = pd.concat([existing_df, pd.DataFrame(results)])\n",
        "  else:\n",
        "      df = pd.DataFrame(results)\n",
        "  wb = Workbook()\n",
        "  ws = wb.active\n",
        "  for r in dataframe_to_rows(df, index=False, header=True):\n",
        "      ws.append(r)\n",
        "  wb.save(file_name)"
      ],
      "metadata": {
        "id": "JnvN2_VlDWT9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = 'Immagini_satellitari/Train'\n",
        "test_path = 'Immagini_satellitari/Test/'\n",
        "model_name = \"rf_splitlen(X1)_GridSearch_model.h\"\n",
        "param = 'rf split len(X1) GridSearch'\n",
        "param_grid = {\n",
        "    \"class_weight\": [{0: 1, 1: 1}, {0: 1, 1: 2}, {0: 1, 1: 3}, {0: 1, 1: 4}, {0: 1, 1: 5},\n",
        "     {0: 1, 1: 6},{0: 1, 1: 7},{0: 1, 1: 8},{0: 1, 1: 9},{0: 1, 1: 10},\n",
        "                     {0: 1, 1: 15}, {0: 1, 1: 30}, \"balanced\"],\n",
        "    \"max_depth\": [7, 8, 9 ,10],\n",
        "    \"max_samples\": [0.8, 0.9, 1.0],\n",
        "    \"criterion\": [\"entropy\", \"gini\", \"gini\"],\n",
        "    \"max_features\": [\"sqrt\", \"log2\"]\n",
        "}\n",
        "\n",
        "trainX,trainY = loaddataset(train_path)\n",
        "testX,testY = loaddataset(test_path)\n",
        "\n",
        "X1,Y1 = selectSet(trainX, trainY, 1)\n",
        "X0,Y0 = selectSet(trainX, trainY, 0)\n",
        "X1,Y1 = sampling(X1, Y1, len(X1))\n",
        "X0,Y0 = sampling(X0, Y0, len(X1))\n",
        "X,Y = concatenate(X1, X0, Y1, Y0)\n",
        "grindsearch(param_grid,X,Y,model_name)\n",
        "\n",
        "test_predictions = rftest(testX,model_name)\n",
        "print(\"TEST : \")\n",
        "print_metrics(testY,test_predictions)\n",
        "save_csv(model_name, 'Test Set', param, testY, test_predictions)\n",
        "\n",
        "train_predictions = rftest(trainX,model_name)\n",
        "print(\"TRAIN : \")\n",
        "print_metrics(trainY,train_predictions)\n",
        "save_csv(model_name, 'Train Set', param, trainY, train_predictions)\n",
        "\n",
        "sample_predictions = rftest(X,model_name)\n",
        "print(\"Sample TRAIN : \")\n",
        "print_metrics(Y,sample_predictions)\n",
        "save_csv(model_name, 'Sample Set', param, Y, sample_predictions)"
      ],
      "metadata": {
        "id": "DxdmzMQ_ergz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92123e4f-4ffd-4af9-b8b1-1762277fd2b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST : \n",
            "True Negative (TN): 76916\n",
            "False Negative (FN): 1294\n",
            "False Positive (FP): 85184\n",
            "True Positive (TP): 1470\n",
            "Precision (Negative Class): 0.9834548011763201\n",
            "Recall (Negative Class): 0.4744972239358421\n",
            "F-score (Negative Class): 0.6401398193999417\n",
            "Precision (Positive Class): 0.016964017817988782\n",
            "Recall (Positive Class): 0.5318379160636758\n",
            "F-score (Positive Class): 0.03287928604978863\n",
            "Average Accuracy: 39193.23772927989\n",
            "Overall Accuracy: 0.4754585597826087\n",
            "G-Mean: 0.5023500918244542\n",
            "AUC (Area Under the Curve): 0.503167569999759\n",
            "\n",
            "\n",
            "TRAIN : \n",
            "True Negative (TN): 330013\n",
            "False Negative (FN): 4370\n",
            "False Positive (FP): 316152\n",
            "True Positive (TP): 19161\n",
            "Precision (Negative Class): 0.9869311537966942\n",
            "Recall (Negative Class): 0.5107255886654337\n",
            "F-score (Negative Class): 0.6731195209209543\n",
            "Precision (Positive Class): 0.057143624016963254\n",
            "Recall (Positive Class): 0.8142875355913476\n",
            "F-score (Positive Class): 0.10679292394466676\n",
            "Average Accuracy: 174587.26069589783\n",
            "Overall Accuracy: 0.5213917956804281\n",
            "G-Mean: 0.6448856340141377\n",
            "AUC (Area Under the Curve): 0.6625065621283907\n",
            "\n",
            "\n",
            "Sample TRAIN : \n",
            "True Negative (TN): 12996\n",
            "False Negative (FN): 4370\n",
            "False Positive (FP): 10535\n",
            "True Positive (TP): 19161\n",
            "Precision (Negative Class): 0.7483588621444202\n",
            "Recall (Negative Class): 0.5522927202413838\n",
            "F-score (Negative Class): 0.6355478396948433\n",
            "Precision (Positive Class): 0.6452384159482759\n",
            "Recall (Positive Class): 0.8142875355913476\n",
            "F-score (Positive Class): 0.7199729460612095\n",
            "Average Accuracy: 16078.841645063958\n",
            "Overall Accuracy: 0.6832901279163657\n",
            "G-Mean: 0.67061544725006\n",
            "AUC (Area Under the Curve): 0.6832901279163656\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}